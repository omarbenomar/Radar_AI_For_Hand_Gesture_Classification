{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfd963df",
   "metadata": {},
   "source": [
    "# CNN 1D:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f038cb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalAveragePooling1D, Input, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4e2001",
   "metadata": {},
   "source": [
    "**Data Loading and Feature Extraction:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fc0783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Feature Extraction Functions ---\n",
    "#Need to develop your own feature extraction functions based on a method called 'Classification of micro-Doppler radar hand-gesture signatures by means of Chebyshev moments\n",
    "# --- Data Loading  ---\n",
    "\n",
    "base_path='/Users/beno/Desktop/TU DELFT/ML for EE/WICOS' #A CHANGER!\n",
    "people = ['Person A', 'Person B', 'Person C', 'Person D', 'Person E', 'Person F']  \n",
    "gestures = ['click', 'pinch', 'swipe', 'wave']\n",
    "\n",
    "X_all = [] \n",
    "y_all = []\n",
    "\n",
    "print(\"Loading and extracting 1D envelope features...\")\n",
    "for person in people:\n",
    "    for gesture in gestures:\n",
    "        gesture_path = os.path.join(base_path, person, gesture)\n",
    "        if os.path.exists(gesture_path):\n",
    "            files = [f for f in os.listdir(gesture_path) if f.endswith('.csv')]\n",
    "            for f in files:\n",
    "                df = pd.read_csv(os.path.join(gesture_path, f), dtype=np.float32)\n",
    "                \n",
    "                #  Preprocess spectrogram\n",
    "                matrix, freqs = preprocess_spectrogram(df)\n",
    "                \n",
    "                #  Extract 1D Envelopes\n",
    "                eU, eL = extract_envelopes(matrix, freqs)\n",
    "                \n",
    "                # Build augmented feature vector (as per paper)\n",
    "                feature_vector = build_feature_vector(eU, eL)\n",
    "                \n",
    "                # Append 1D vector and label\n",
    "                X_all.append(feature_vector)\n",
    "                y_all.append(gesture)\n",
    "        else:\n",
    "            print(f\"Warning: Data directory not found for {person}/{gesture}\")\n",
    "\n",
    "print(f\"Loaded {len(X_all)} total samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efe764f",
   "metadata": {},
   "source": [
    "**Data Preparation for 2D CNN:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7a050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad all 1D feature vectors to be the same size\n",
    "X_padded = pad_to_max_length(X_all)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "label_encoder = LabelEncoder()\n",
    "y_int = label_encoder.fit_transform(y_all)\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "y_oh = onehot_encoder.fit_transform(y_int.reshape(-1, 1))\n",
    "\n",
    "# Add a \"channels\" dimension for the 1D CNN\n",
    "# Shape becomes (num_samples, max_length, 1)\n",
    "X_cnn_1d = np.expand_dims(X_padded, axis=2)\n",
    "\n",
    "# Get input shape and number of classes\n",
    "input_shape = X_cnn_1d.shape[1:]\n",
    "num_classes = y_oh.shape[1]\n",
    "\n",
    "# Create Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_cnn_1d, y_oh, test_size=0.2, random_state=42, stratify=y_all\n",
    ")\n",
    "\n",
    "print(f\"X_train shape for 1D CNN: {X_train.shape}\")\n",
    "print(f\"y_train shape for 1D CNN: {y_train.shape}\")\n",
    "print(f\"Input shape for 1D CNN: {input_shape}\")\n",
    "print(f\"Number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d65ea6",
   "metadata": {},
   "source": [
    "**Defining the CNN model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3553263",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1d = Sequential()\n",
    "\n",
    "# Input Layer - shape is (timesteps, features=1)\n",
    "model_1d.add(Input(shape=input_shape))\n",
    "\n",
    "# Convolutional Block 1\n",
    "model_1d.add(Conv1D(filters=16, kernel_size=3, activation='relu', padding='same'))\n",
    "model_1d.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# Convolutional Block 2\n",
    "model_1d.add(Conv1D(filters=32, kernel_size=3, activation='relu', padding='same'))\n",
    "model_1d.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# Convolutional Block 3\n",
    "model_1d.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='same'))\n",
    "\n",
    "# Use GlobalAveragePooling1D to reduce parameters and handle sequences\n",
    "model_1d.add(GlobalAveragePooling1D())\n",
    "\n",
    "# Dropout for regularization\n",
    "model_1d.add(Dropout(0.5))\n",
    "\n",
    "# Output layer\n",
    "model_1d.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_1d.compile(loss='categorical_crossentropy',\n",
    "                 optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "model_1d.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5abdd6d",
   "metadata": {},
   "source": [
    "**Model Training:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1faae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MODEL TRAINING ---\n",
    "print(\"\\nTraining 1D CNN model...\")\n",
    "history = model_1d.fit(X_train, y_train,\n",
    "                       epochs=50,  # This simpler model can train for more epochs\n",
    "                       batch_size=32,\n",
    "                       validation_data=(X_test, y_test))\n",
    "\n",
    "# --- MODEL EVALUATION ---\n",
    "print(\"\\nEvaluating 1D CNN model...\")\n",
    "y_pred_probs = model_1d.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_labels, y_pred, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5571058c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
